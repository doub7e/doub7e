---
---

@article{li2025learning,
  title={Learning to Weight Parameters for Data Attribution},
  author={Li, Shuangqi and Le, Hieu and Xu, Jingyi and Salzmann, Mathieu},
  abstract={We study data attribution in generative models, aiming to identify which training examples most influence a given output. Existing methods achieve this by tracing gradients back to training data. However, they typically treat all network parameters uniformly, ignoring the fact that different layers encode different types of information and may thus draw information differently from the training set. We propose a method that models this by learning parameter importance weights tailored for attribution, without requiring labeled data. This allows the attribution process to adapt to the structure of the model, capturing which training examples contribute to specific semantic aspects of an output, such as subject, style, or background. Our method improves attribution accuracy across diffusion models and enables fine-grained insights into how outputs borrow from training data.},
  journal={arXiv preprint arXiv:2506.05647},
  pdf={https://arxiv.org/pdf/2506.05647},
  year={2025},
  selected={true},
}

@inproceedings{li2024enhancing,
  title={Enhancing compositional text-to-image generation with reliable random seeds},
  author={Li, Shuangqi and Le, Hieu and Xu, Jingyi and Salzmann, Mathieu},
  abstract={Text-to-image diffusion models have demonstrated remarkable capability in generating realistic images from arbitrary text prompts. However, they often produce inconsistent results for compositional prompts such as "two dogs" or "a penguin on the right of a bowl". Understanding these inconsistencies is crucial for reliable image generation. In this paper, we highlight the significant role of initial noise in these inconsistencies, where certain noise patterns are more reliable for compositional prompts than others. Our analyses reveal that different initial random seeds tend to guide the model to place objects in distinct image areas, potentially adhering to specific patterns of camera angles and image composition associated with the seed. To improve the model's compositional ability, we propose a method for mining these reliable cases, resulting in a curated training set of generated images without requiring any manual annotation. By fine-tuning text-to-image models on these generated images, we significantly enhance their compositional capabilities. For numerical composition, we observe relative increases of 29.3\% and 19.5\% for Stable Diffusion and PixArt-\alpha, respectively. Spatial composition sees even larger gains, with 60.7\% for Stable Diffusion and 21.1\% for PixArt-\alpha.},
  booktitle={The Thirteenth International Conference on Learning Representations (Spotlight)},
  pdf={https://openreview.net/pdf?id=5BSlakturs},
  year={2024},
  selected={true},
}

@article{li2024controlling,
  title={Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density},
  author={Li, Shuangqi and Liu, Chen and Zhang, Tong and Le, Hieu and S{\"u}sstrunk, Sabine and Salzmann, Mathieu},
  abstract={We introduce an approach to bias deep generative models, such as GANs and diffusion models, towards generating data with either enhanced fidelity or increased diversity. Our approach involves manipulating the distribution of training and generated data through a novel metric for individual samples, named pseudo density, which is based on the nearest-neighbor information from real samples. Our approach offers three distinct techniques to adjust the fidelity and diversity of deep generative models: 1) Per-sample perturbation, enabling precise adjustments for individual samples towards either more common or more unique characteristics; 2) Importance sampling during model inference to enhance either fidelity or diversity in the generated data; 3) Fine-tuning with importance sampling, which guides the generative model to learn an adjusted distribution, thus controlling fidelity and diversity. Furthermore, our fine-tuning method demonstrates the ability to improve the Frechet Inception Distance (FID) for pre-trained generative models with minimal iterations},
  journal={Transactions on Machine Learning Research (presented as a poster at ICLR 2025)},
  pdf={https://arxiv.org/pdf/2407.08659},
  year={2024},
  selected={true},
}

@article{li2022interlock,
  title={Interlock-free multi-aspect rationalization for text classification},
  author={Li, Shuangqi and Antognini, Diego and Faltings, Boi},
  abstract={Explanation is important for text classification tasks. One prevalent type of explanation is rationales, which are text snippets of input text that suffice to yield the prediction and are meaningful to humans. A lot of research on rationalization has been based on the selective rationalization framework, which has recently been shown to be problematic due to the interlocking dynamics. In this paper, we show that we address the interlocking problem in the multi-aspect setting, where we aim to generate multiple rationales for multiple outputs. More specifically, we propose a multi-stage training method incorporating an additional self-supervised contrastive loss that helps to generate more semantically diverse rationales. Empirical results on the beer review dataset show that our method improves significantly the rationalization performance.},
  journal={arXiv preprint arXiv:2205.06756},
  pdf={https://arxiv.org/pdf/2205.06756},
  year={2022}
}



% @article{PhysRev.47.777,
%   abbr={PhysRev},
%   title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
%   author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
%   abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
%   journal={Phys. Rev.},
%   location={New Jersey},
%   volume={47},
%   issue={10},
%   pages={777--780},
%   numpages={0},
%   year={1935},
%   month={May},
%   publisher=aps,
%   doi={10.1103/PhysRev.47.777},
%   url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
%   html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
%   pdf={example_pdf.pdf},
%   altmetric={248277},
%   dimensions={true},
%   google_scholar_id={qyhmnyLat1gC},
%   video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
%   additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
%   annotation={* Example use of superscripts<br>† Albert Einstein},
%   selected={true},
%   inspirehep_id = {3255}
% }